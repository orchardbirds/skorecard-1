import pandas as pd
import numpy as np
from typing import Optional
import warnings

from sklearn.utils.validation import check_is_fitted

from skorecard.bucket_mapping import BucketMapping
import skorecard.bucketers


def build_bucket_table(
    X: pd.DataFrame,
    y: np.ndarray,
    column: str,
    bucketer=None,
    bucket_mapping: Optional[BucketMapping] = None,
    epsilon=0.00001,
    display_missing=True,
    verbose=False,
) -> pd.DataFrame:
    """
    Calculates summary statistics for a bucket generated by a skorecard bucketing object.

    This report currently works for just 1 column at a time.

    ``python
    from skorecard import datasets
    from skorecard.bucketers import DecisionTreeBucketer
    from skorecard.reporting import create_report
    X, y = datasets.load_uci_credit_card(return_X_y=True)

    # make sure that those cases
    specials = {
        "LIMIT_BAL":{
            "=50000":[50000],
            "in [20001,30000]":[20000,30000],
            }
    }

    dt_bucketer = DecisionTreeBucketer(variables=['LIMIT_BAL'], specials = specials)
    dt_bucketer.fit(X, y)
    dt_bucketer.transform(X)

    df_report = create_report(X,y,column="LIMIT_BAL", bucketer= dt_bucketer)
    df_report
    ```

    Args:
         X (pd.DataFrame): features
         y (np.array): target
         column (str): column for which you want the report
         bucketer: (optional) Skorecard.bucketing bucketer object. Ignored if bucket_mapping is specified.
         bucket_mapping: (optional) Skorecard.bucket_mapping BucketMapping object
         epsilon(float): small value to prevent zero division error for WoE
         display_missing (boolean): Add a row for missing even when not present in data
         verbose(boolean): be verbose

    Returns:
        df (pandas DataFrame): reporting df
    """
    assert column in X.columns

    X = X.copy()

    if bucket_mapping and bucketer:
        warnings.warn("Both bucket_mapping and bucketer specified. Ignoring bucketer.")

    if not bucket_mapping and not bucketer:
        raise Exception("Specify either bucket_mapping or bucketer")
        # TODO: In case no bucket_mapping and no bucketer specified,use values as-is

    if bucket_mapping and not bucketer:
        col_bucket_mapping = bucket_mapping

    if not bucket_mapping and bucketer:
        if isinstance(bucketer, skorecard.bucketers.UserInputBucketer):
            bucket_dict = bucketer.features_bucket_mapping_.maps
        else:
            bucket_dict = bucketer.features_bucket_mapping_

        col_bucket_mapping = bucket_dict[column]

    X_transform = pd.DataFrame(data={"bucket_id": col_bucket_mapping.transform(X[column])})
    if y is not None:
        X_transform["Event"] = y
    else:
        X_transform["Event"] = np.nan

    stats = X_transform.groupby("bucket_id", as_index=False).agg(
        def_rate=pd.NamedAgg(column="Event", aggfunc="mean"),
        Event=pd.NamedAgg(column="Event", aggfunc="sum"),
        Count=pd.NamedAgg(column="bucket_id", aggfunc="count"),
    )

    stats["label"] = stats["bucket_id"].map(col_bucket_mapping.labels)

    # Make sure missing is present even when not present
    if display_missing:
        ref = pd.DataFrame.from_dict(col_bucket_mapping.labels, orient="index", columns=["label"])
        ref["bucket_id"] = ref.index
        stats = (
            stats.merge(ref, how="outer", on=["bucket_id", "label"])
            .fillna(0)
            .sort_values("bucket_id")
            .reset_index(drop=True)
        )

    stats["Count (%)"] = stats["Count"] / stats["Count"].sum()

    # If unsupervised bucketer, we don't always have y info.
    if y is None:
        columns = ["bucket_id", "label", "Count", "Count (%)"]
        return stats.sort_values(by="bucket_id")[columns]

    stats["Non-event"] = stats["Count"] - stats["Event"]
    # Default rates
    stats["Event Rate"] = stats["Event"] / stats["Count"]  # TODO: can we divide by 0 accidentally?

    stats["% Event"] = stats["Event"] / stats["Event"].sum()
    stats["% Non-event"] = stats["Non-event"] / stats["Non-event"].sum()

    stats["WoE"] = ((stats["% Event"] + epsilon) / (stats["% Non-event"] + epsilon)).apply(lambda x: np.log(x))
    stats["IV"] = (stats["% Event"] - stats["% Non-event"]) * stats["WoE"]

    stats["WoE"] = round(stats["WoE"], 2)
    stats["IV"] = round(stats["IV"], 2)

    if verbose:
        iv_total = stats["IV"].sum()
        print(f"IV for {column} = {np.round(iv_total, 4)}")

    columns = [
        "bucket_id",
        "label",
        "Count",
        "Count (%)",
        "Non-event",
        "Event",
        "Event Rate",
        "WoE",
        "IV",
    ]
    return stats.sort_values(by="bucket_id")[columns]


class BucketTableMethod:
    """
    Add method for bucketing tables to another class.

    To be used with skorecard.pipeline.BucketingProcess and skorecard.bucketers.BaseBucketer
    """

    def bucket_table(self, column):
        """
        Generates the statistics for the buckets of a particular column.

        The pre-buckets are matched to the post-buckets, so that the user has a much clearer understanding of how
        the BucketingProcess ends up with the final buckets.
        An example is seen below:

        bucket     | label              | Count | Count (%) | Non-event | Event | Event Rate | WoE |  IV
        ---------------------------------------------------------------------------------------------------
        0          | (-inf, 25000.0)    | 479.0 | 7.98      | 300.0     | 179.0 | 37.37      | 0.73 | 0.05
        1          | [25000.0, 45000.0) | 370.0 | 6.17      | 233.0     | 137.0 | 37.03      | 0.71 | 0.04

        Args:
            column: The column we wish to analyse

        Returns:
            df (pd.DataFrame): A pandas dataframe of the format above
        """  # noqa
        check_is_fitted(self)
        if column not in self.bucket_tables_.keys():
            raise ValueError(f"column '{column}' was not part of the bucketingprocess")

        table = self.bucket_tables_.get(column)
        table = table.rename(columns={"bucket_id": "bucket"})

        return table


class PreBucketTableMethod:
    """
    Add method for bucketing tables to another class.

    To be used with skorecard.pipeline.BucketingProcess and skorecard.bucketers.BaseBucketer
    """

    def prebucket_table(self, column):
        """
        Generates the statistics for the buckets of a particular column.

        An example is seen below:

        pre-bucket | label      | Count | Count (%) | Non-event | Event | Event Rate | WoE   | IV  | bucket
        ---------------------------------------------------------------------------------------------------
        0          | (-inf, 1.0)| 479   | 7.98      | 300       | 179   |  37.37     |  0.73 | 0.05 | 0
        1          | [1.0, 2.0) | 370   | 6.17      | 233       | 137   |  37.03     |  0.71 | 0.04 | 0

        Args:
            column: The column we wish to analyse

        Returns:
            df (pd.DataFrame): A pandas dataframe of the format above
        """  # noqa
        check_is_fitted(self)
        if column not in self.prebucket_tables_.keys():
            raise ValueError(f"column '{column}' was not part of the pre-bucketing process")

        table = self.prebucket_tables_.get(column)
        table = table.rename(columns={"bucket_id": "pre-bucket"})

        # Apply bucket mapping
        bucket_mapping = self.features_bucket_mapping_.get(column)
        table["bucket"] = bucket_mapping.transform(table["pre-bucket"])
        return table
