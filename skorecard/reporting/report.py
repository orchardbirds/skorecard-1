import pandas as pd
import numpy as np
from typing import Union, Optional
import warnings

from skorecard.bucket_mapping import BucketMapping
from skorecard.bucketers import UserInputBucketer


def bucket_table(
    x_original: pd.Series,
    x_bucketed: pd.Series,
    y: Union[pd.Series, np.array],
    bucket_mapping: Optional[BucketMapping] = None,
    epsilon: float = 0.00001,
) -> pd.DataFrame:
    """Create a table with results of bucketing.

    Example:

    ```python
    from skorecard import datasets
    from skorecard.bucketers import DecisionTreeBucketer
    from skorecard.reporting import bucket_table

    X, y = datasets.load_uci_credit_card(return_X_y=True)
    db = DecisionTreeBucketer(max_n_bins=7, min_bin_size=0.05)
    X_trans = db.fit_transform(X, y)
    x_original = X['BILL_AMT1']
    x_bucketed = X_trans['BILL_AMT1']

    bucket_table(x_original, x_bucketed, y)

    # or with a bucket_mapping for nice bucket range printing
    bucket_table(x_original, x_bucketed, y,
        bucket_mapping = db.features_bucket_mapping_.get('BILL_AMT1')
    )
    ```
    """
    ref = pd.DataFrame()
    ref["original"] = x_original
    ref["bucket"] = x_bucketed
    ref["y"] = y

    table = ref.groupby("bucket")["original"].agg(["min", "max", "count"]).reset_index()
    table["range"] = table["min"].astype(str) + " - " + table["max"].astype(str)
    table = table.drop(columns=["min", "max"])
    table = table[["bucket", "range", "count"]]

    # Add bucket map as range, if available.
    if bucket_mapping:
        # note that the buckets are sorted, so we can use that order
        table["range"] = table["bucket"].replace(table["bucket"].unique(), bucket_mapping.get_map())

    # Add counts %
    table["count %"] = round((table["count"] / table["count"].sum()) * 100, 2)
    # table["count %"] = table["count %"].astype(str) + "%"

    # Add event rates
    er = ref.groupby(["bucket", "y"]).agg({"y": ["count"]}).reset_index()
    er.columns = [" ".join(col).strip() for col in er.columns.values]
    er = er.pivot(index="bucket", columns="y", values="y count")
    er = er.rename(columns={0: "Non-event", 1: "Event"})
    er["Event Rate"] = round((er["Event"] / (er["Event"] + er["Non-event"])) * 100, 2)
    # er["Event Rate"] = er["Event Rate"].astype(str) + "%"
    table = table.merge(er, how="left", on="bucket")

    # Add WoE and IV
    table["% Event"] = table["Event"] / table["Event"].sum()
    table["% Non Event"] = table["Non-event"] / table["Non-event"].sum()
    table["WoE"] = ((table["% Event"] + epsilon) / (table["% Non Event"] + epsilon)).apply(lambda x: np.log(x))
    table["WoE"] = round(table["WoE"], 3)
    table["IV"] = (table["% Event"] - table["% Non Event"]) * table["WoE"]
    table["IV"] = round(table["IV"], 3)
    table = table.drop(columns=["% Event", "% Non Event"])

    return table


def create_report(
    X: pd.DataFrame,
    y: np.array,
    column: str,
    bucketer=None,
    bucket_mapping: Optional[BucketMapping] = None,
    epsilon=0.00001,
    verbose=False,
) -> pd.DataFrame:
    """Calculates summary statistics for a bucket generated by a skorecard bucketing object.

    This report currently works for just 1 column at a time.

    ``python
    from skorecard import datasets
    from skorecard.bucketers import DecisionTreeBucketer
    from skorecard.reporting import create_report
    X, y = datasets.load_uci_credit_card(return_X_y=True)

    # make sure that those cases
    specials = {
        "LIMIT_BAL":{
            "=50000":[50000],
            "in [20001,30000]":[20000,30000],
            }
    }

    dt_bucketer = DecisionTreeBucketer(variables=['LIMIT_BAL'], specials = specials)
    dt_bucketer.fit(X, y)
    dt_bucketer.transform(X)

    df_report = create_report(X,y,column="LIMIT_BAL", bucketer= dt_bucketer)
    df_report
    ```

    Args:
         X (pd.DataFrame): features
         y (np.array): target
         column (str): column for which you want the report
         bucketer: (optional) Skorecard.bucketing bucketer object. Ignored if bucket_mapping is specified.
         bucket_mapping: (optional) Skorecard.bucket_mapping BucketMapping object
         epsilon(float): small value to prevent zero division error for WoE
         verbose(boolean): be verbose

    Returns:
        df (pandas DataFrame): reporting df
    """
    X = X.copy()

    if bucket_mapping and bucketer:
        warnings.warn("Both bucket_mapping and bucketer specified. Ignoring bucketer.")

    if not bucket_mapping and not bucketer:
        raise Exception("Specify either bucket_mapping or bucketer")

    if bucket_mapping and not bucketer:
        col_bucket_mapping = bucket_mapping

    if not bucket_mapping and bucketer:
        if isinstance(bucketer, UserInputBucketer):
            bucket_dict = bucketer.features_bucket_mapping_.maps
        else:
            bucket_dict = bucketer.features_bucket_mapping_

        col_bucket_mapping = bucket_dict[column]

    # In case no bucket_mapping and no bucketer specified,use values as-is
    X_transform = pd.DataFrame(data={"bucket_id": col_bucket_mapping.transform(X[column])})

    X_transform["Event"] = y

    stats = X_transform.groupby("bucket_id", as_index=False).agg(
        def_rate=pd.NamedAgg(column="Event", aggfunc="mean"),
        Event=pd.NamedAgg(column="Event", aggfunc="sum"),
        Count=pd.NamedAgg(column="bucket_id", aggfunc="count"),
    )

    stats["label"] = stats["bucket_id"].map(col_bucket_mapping.labels)
    stats["Count (%)"] = (stats["Count"] / stats["Count"].sum()).apply(lambda x: np.round(x * 100, 2))

    stats["Non-event"] = stats["Count"] - stats["Event"]
    # Default rates
    stats["Event Rate"] = stats["Event"] / stats["Count"]  # TODO: can we divide by 0 accidentally?

    stats["% Event"] = stats["Event"] / stats["Event"].sum()
    stats["% Non-event"] = stats["Non-event"] / stats["Non-event"].sum()

    stats["WoE"] = ((stats["% Event"] + epsilon) / (stats["% Non-event"] + epsilon)).apply(lambda x: np.log(x))
    stats["IV"] = (stats["% Event"] - stats["% Non-event"]) * stats["WoE"]

    if verbose:
        iv_total = stats["IV"].sum()
        print(f"IV for {column} = {np.round(iv_total, 4)}")

    columns = [
        "bucket_id",
        "label",
        "Count",
        "Count (%)",
        "Non-event",
        "Event",
        "Event Rate",
        "WoE",
        "IV",
    ]
    return stats.sort_values(by="bucket_id")[columns]
