{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from skorecard import datasets\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# from skorecard.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from feature_engine.discretisers import EqualWidthDiscretiser\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "in `skorecard` there is a demo dataset with 4 features (2 categorical and 2 numerical) for demo and testing.<br>\n",
    "We'll use this one here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_uci_credit_card(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['MARRIAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['LIMIT_BAL'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['BILL_AMT1'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify categorical and numerical columns\n",
    "\n",
    "#### We'll autodetect using dabl.detect_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dabl import detect_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_types = detect_types(X)\n",
    "detected_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = X.columns[(detected_types['categorical']==True) | (detected_types['low_card_int']==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = X.columns[(detected_types['continuous']==True) | (detected_types['dirty_float']==True)]\n",
    "print(f\"cat_columns = {cat_columns}\")\n",
    "print(f\"num_columns = {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucketers\n",
    "\n",
    "The core of `skorecard` are the bucketers.<br>\n",
    "\n",
    "All bucketeres are `transformer`: in other words they can be used with `sklearn` pipelines\n",
    "\n",
    "The bucketers rely on `probatus` to perform the bucketing.<br>\n",
    "\n",
    "The bucketers are:\n",
    "\n",
    "- EqualWidthBucketer (histogram)\n",
    "- EqualFrequencyBucketer (quantiles)\n",
    "- AgglomerativeClusteringBucketer (uses agglomerative clustering to put the data together)\n",
    "- DecisionTreeBucketer (uses a decision tree to find the optimal bucketer)\n",
    "- OrdinalCategoricalBucketer(used for categorical features)\n",
    "\n",
    "### EqualWidthBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucketers import EqualWidthBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWB = EqualWidthBucketer(bins = 5) # show non-int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWB.fit(X['LIMIT_BAL']) # this breaks - needs pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWB.fit(X[['LIMIT_BAL']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the probatus bucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWB.bucketer # Note the equal (well, almost) widths!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One of the main components of `skorecard`: `FeaturesBucketMapping`\n",
    "\n",
    "`FeaturesBucketMapping` it's a dictionary extensions that stores the bucketing in a format that is shareable accross different componenets.\n",
    "\n",
    "After the bucketer is fitted, the attirbute `features_bucket_mapping_`  is a dictionary with {'feature name': FeaturesBucketMapping}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWB.features_bucket_mapping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = EWB.transform(X[['LIMIT_BAL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform['LIMIT_BAL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple features at the same time\n",
    "\n",
    "Every bucketer accepts a keyword `variables`, which is a list of columns you want to apply the bucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EWB = EqualWidthBucketer(bins = 5, variables=['LIMIT_BAL','BILL_AMT1']) # show non-int\n",
    "\n",
    "EWB.fit_transform(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EqualFrequencyBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucketers import EqualFrequencyBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFB = EqualFrequencyBucketer(bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFB.fit(X[['BILL_AMT1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFB.features_bucket_mapping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFB.bucketer # Note the counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the counts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = EFB.transform(X[['BILL_AMT1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not always perfect: LIMIT_BAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFB = EqualFrequencyBucketer(bins = 5)\n",
    "EFB.fit(X[['LIMIT_BAL']])\n",
    "EFB.bucketer # Note the counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the feature is skewed, it's not ideal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['LIMIT_BAL']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucketers import AgglomerativeClusteringBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACB = AgglomerativeClusteringBucketer(bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACB.fit(X[['BILL_AMT1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACB.bucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = ACB.transform(X[['BILL_AMT1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucketers import OrdinalCategoricalBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCB = OrdinalCategoricalBucketer(tol=0.15, max_n_categories=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCB.fit(X[['MARRIAGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = OCB.transform(X[['MARRIAGE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['MARRIAGE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transformation - buckets get merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And if we increase tol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCB = OrdinalCategoricalBucketer(tol=0.50, max_n_categories=None)\n",
    "OCB.fit(X[['MARRIAGE']])\n",
    "X_transform = OCB.transform(X[['MARRIAGE']])\n",
    "X_transform.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucketers import DecisionTreeBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB = DecisionTreeBucketer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB.fit(X[['LIMIT_BAL']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = DTB.transform(X[['LIMIT_BAL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform['LIMIT_BAL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB.bucketer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too many bins!!!\n",
    "\n",
    "If you look at the decision tree, it used the sklearn default hyperparameters.<br>\n",
    "Those trees overfit (as they grow as long as possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB = DecisionTreeBucketer(\n",
    "    max_depth=4, # allow a maximum of 16 bins (2^4)\n",
    "   min_samples_leaf=0.1, # do not allow bins to go below 10% ,\n",
    "   # min_impurity_decrease = 0.00005\n",
    ")\n",
    "\n",
    "DTB.fit(\n",
    "    X[['LIMIT_BAL']],\n",
    "    y # Need the target for the training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for every bin, it does not drop below 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB.bucketer.counts/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB.features_bucket_mapping_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a sklearn pipeline\n",
    "\n",
    "Putting together, there are multiple options!\n",
    "\n",
    "Use make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_pipeline = make_pipeline(\n",
    "    EqualWidthBucketer(bins=5, variables=list(num_columns)),\n",
    "    OrdinalCategoricalBucketer(variables=list(cat_columns))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bucketing', bucket_pipeline), ### Make the buckets\n",
    "    ('one-hot-encoding', OneHotEncoder()), ### One-Hot encode them\n",
    "    ('lr', LogisticRegression()) ### Pass through Logistic Regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline check\n",
    "\n",
    "One hot encode the categorical features, do nothing with the numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a ColumnTransformer\n",
    "\n",
    "ohe_pipeline = ColumnTransformer([\n",
    "    ('ohe_cat_preprocessing', OneHotEncoder(),cat_columns),\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# bucket_pipeline.fit_transform(X, y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('ohe', ohe_pipeline),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try now with a decision tree bucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_pipeline = make_pipeline(\n",
    "    DecisionTreeBucketer(max_depth=4,min_samples_leaf=0.1, variables=list(num_columns)),\n",
    "    OrdinalCategoricalBucketer(variables=list(cat_columns))\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bucketing', bucket_pipeline),\n",
    "    ('one-hot-encoding', OneHotEncoder()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative - use the column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a ColumnTransformer\n",
    "\n",
    "bucket_pipeline = ColumnTransformer([\n",
    "    ('categorical_preprocessing', OrdinalCategoricalBucketer(), ['EDUCATION', 'MARRIAGE']),\n",
    "    ('numerical_preprocessing', DecisionTreeBucketer(max_depth=4,min_samples_leaf=0.1), ['LIMIT_BAL','BILL_AMT1'])\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "# bucket_pipeline.fit_transform(X, y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bucketing', bucket_pipeline),\n",
    "    ('one-hot-encoding', OneHotEncoder()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the best performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_pipeline = make_pipeline(\n",
    "    DecisionTreeBucketer(max_depth=4,min_samples_leaf=0.1, variables=list(num_columns)),\n",
    "    OrdinalCategoricalBucketer(tol=0.15,variables=list(cat_columns))\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bucketing', bucket_pipeline),\n",
    "    ('one-hot-encoding', OneHotEncoder()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the bucketers from the pipeline \n",
    "handy function is now WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_bucket_mapping = bucket_pipeline.steps[0][1].features_bucket_mapping_.copy()\n",
    "\n",
    "(\n",
    "    all_features_bucket_mapping\n",
    "    .update(bucket_pipeline.steps[1][1].features_bucket_mapping_)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_bucket_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The user input bucketer\n",
    "\n",
    "Probably, some manual tweaking might be required. \n",
    "\n",
    "Therefore ther eis a UserInputBucketer, that requires a `feature_bucket_mapping` and applies it over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucketers import UserInputBucketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIbucketers = UserInputBucketer(all_features_bucket_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it in a pipeine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UI_pipeline = Pipeline([\n",
    "    ('bucketing', UIbucketers),\n",
    "    ('one-hot-encoding', OneHotEncoder()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "UI_pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, UI_pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_bucket_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of manual tweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_input = all_features_bucket_mapping.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.bucket_mapping import BucketMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_input['BILL_AMT1'] = BucketMapping(\n",
    "    feature_name='BILL_AMT1', \n",
    "    type='numerical', \n",
    "    map=[-165580.0, 293.5, 2559.5, 13047.0, \n",
    "       #  21671.5, #merge the 3rd and 4th bucket together\n",
    "         36140.5, 62541.0, 101520.0, 610723.0], \n",
    "    right=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualUIbucketers = UserInputBucketer(manual_input)\n",
    "\n",
    "manual_UI_pipeline = Pipeline([\n",
    "    ('bucketing', manualUIbucketers),\n",
    "    ('one-hot-encoding', OneHotEncoder()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "manual_UI_pipeline.fit(X, y)\n",
    "f\"AUC = {roc_auc_score(y, manual_UI_pipeline.predict_proba(X)[:,1]):.4f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The web app - still WIP\n",
    "\n",
    "A webapp is now WIP that will allow to manually inspect and tweak the buckets, and then store them into a BucketMapping object that can be consumed by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorecard.apps import ManualBucketerApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ManualBucketerApp(X,y, manualUIbucketers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}