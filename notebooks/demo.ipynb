{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# skorecard \n",
    "\n",
    "##### building (traditional) credit risk models in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Traditional credit risk modelling\n",
    "\n",
    "When builing a credit risk model, the most commonly used algorithm is a Logisitic Regression, due to its simplicity and interpretability.<br>\n",
    "<br>\n",
    "A Logistic regression is a model that assumes a linear relationship between the variables (aka risk-drivers or features) and the target (the default flag). <br>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- The input variables are usually bucketed (according to statistical process or business knowledge) in order to address the non-linear relationship between variables and risk drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- This generates a set of buckets:\n",
    "    - each feature value gets assigned to one bucket\n",
    "    - the buckets are used to train the model\n",
    "    - using the model output, each bucket is then assigned a score - the final model becomes a scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some practical examples in python\n",
    "\n",
    "- intro to scikit learn\n",
    "- skorecard examples with sklearn integration\n",
    "- sneak preview for the next features in the package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Data\n",
    "\n",
    "in `skorecard` there is a demo dataset with 4 features (2 categorical and 2 numerical) for demo and testing.<br>\n",
    "We'll use it for the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:09:59.938858Z",
     "start_time": "2020-10-14T22:09:59.563751Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skorecard import datasets\n",
    "\n",
    "df = datasets.load_uci_credit_card(as_frame=True)\n",
    "\n",
    "X = df.drop(columns=[\"default\"])\n",
    "y = df[\"default\"]\n",
    "num_cols = [\"LIMIT_BAL\", \"BILL_AMT1\"]\n",
    "cat_cols = [\"EDUCATION\", \"MARRIAGE\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quick intro to scikit-learn\n",
    "\n",
    "- scikit learn (sklearn) is the package that defined the Machine Learning workflow in python.\n",
    "- scikit learn is a very extensive and complete package. In the upcoming two slides we want to introduce the concept of `transformer`, `model` and `pipeline`, as this is what 'skorecard' relates to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### sklearn transformers\n",
    "\n",
    "- `transfromers` are classes in sklearn whose function is to perform a transformation on the data.<br>\n",
    "- in general, a `transformer` preserves the number of rows in a dataset.<br>\n",
    "- 'transformers` are characterized by two main functions:\n",
    "    - `fit(X,y=None)` performs the necessar calculations\n",
    "    - `transfrom(X,y=None)` applies the transformation to the (new) dataset\n",
    "    \n",
    "Example: `MinMaxScaler`: this is a transformer that changes the range of the input features X to a predifined range (normally -1 to 1 or 0,1), depending on the use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.385183Z",
     "start_time": "2020-10-14T22:09:59.940864Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.394370Z",
     "start_time": "2020-10-14T22:10:00.387067Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "X_transformed = mms.transform(X)\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.399556Z",
     "start_time": "2020-10-14T22:10:00.396318Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_transformed[:,0].min(), X_transformed[:,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we change the range for example, we see that the transformation is changed accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.408428Z",
     "start_time": "2020-10-14T22:10:00.401256Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(-2, 2)).fit(X)\n",
    "X_transformed = mms.transform(X)\n",
    "X_transformed[:,0].min(), X_transformed[:,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## sklearn models\n",
    "\n",
    "- models are classes that contain the (ML) models and all that comes along.\n",
    "- A model has three main functions:\n",
    "    - fit(X,y) - runs the optimization for the specific algorithms\n",
    "    - predict(X) - returns the predictions for a new dataset\n",
    "    - predict_proba(X) - returns the probabilities of the fitted model\n",
    "    \n",
    "Example: `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.512324Z",
     "start_time": "2020-10-14T22:10:00.409551Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = (\n",
    "    LogisticRegression()\n",
    "    .fit(X,y)\n",
    ")\n",
    "X_proba = lr.predict_proba(X)\n",
    "X_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## sklearn pipeline - putting it all togeteher\n",
    "\n",
    "A pipeline is a sequential set that puts together transformers and one model.<br>\n",
    "The pipeline can have a sequence of multiple transformers and must finish with a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.539133Z",
     "start_time": "2020-10-14T22:10:00.513967Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "   LogisticRegression()\n",
    ")\n",
    "\n",
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:00.548522Z",
     "start_time": "2020-10-14T22:10:00.542664Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_proba = pipe.predict_proba(X)\n",
    "X_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skorecard - and how it fits in the sklearn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we consider the bucketing process, it fits in the concept of sklearn transformers.<br>\n",
    "Therefore in skorecard, we implemented a set of transformers that map the input data to a set of buckets.\n",
    "\n",
    "Example: bucket with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.071810Z",
     "start_time": "2020-10-14T22:10:00.551109Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skorecard.bucketers import DecisionTreeBucketer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "skorecard_pipeline = make_pipeline(\n",
    "    DecisionTreeBucketer(variables=num_cols, max_n_bins=6, min_bin_size=0.1),\n",
    "    OneHotEncoder(),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.133051Z",
     "start_time": "2020-10-14T22:10:01.073445Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "skorecard_pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get the details of the bucketers\n",
    "\n",
    "Generate a report of the bucketing process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.137530Z",
     "start_time": "2020-10-14T22:10:01.134708Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binner = skorecard_pipeline.steps[0][1] # get the first element of the pipeline, which is our bucketer\n",
    "oh_encoder = skorecard_pipeline.steps[1][1] # get the second element of the pipeline, which is the one hot encoder\n",
    "model = skorecard_pipeline.steps[2][1] # get the third element of the pipeline, which is our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.141934Z",
     "start_time": "2020-10-14T22:10:01.138955Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "binner.features_bucket_mapping_['LIMIT_BAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.629167Z",
     "start_time": "2020-10-14T22:10:01.143250Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skorecard.reporting import create_report\n",
    "\n",
    "create_report(X,y,num_cols[0],binner, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T21:48:05.286251Z",
     "start_time": "2020-10-14T21:48:05.282052Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.634168Z",
     "start_time": "2020-10-14T22:10:01.631023Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:01.638188Z",
     "start_time": "2020-10-14T22:10:01.635565Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Coefficients: {model.coef_}\\n')\n",
    "print(f'Intercept : {model.intercept_}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T21:48:23.397343Z",
     "start_time": "2020-10-14T21:48:23.393350Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fine and coarse classing (WIP)\n",
    "\n",
    "Right now, we have shown an example where:\n",
    "- the binning is defined through one transformer, which might not be optimized\n",
    "- Ideally one would start with a lot of bins (fine classing), and then try to merge them together if they are similar enough (coarse classing)\n",
    "\n",
    "#### skorecard support both and automatic bin merging (based on statistical properties), as well as manual merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:02.427495Z",
     "start_time": "2020-10-14T22:10:01.639428Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from skorecard.bucketers import OptimalBucketer\n",
    "\n",
    "opti_skorecard_pipeline = make_pipeline(\n",
    "    OptimalBucketer(variables=num_cols, max_n_bins=6, min_bin_size=0.1),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "opti_skorecard_pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:02.431701Z",
     "start_time": "2020-10-14T22:10:02.429260Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "opti_binner = opti_skorecard_pipeline.steps[0][1] # get the first element of the pipeline, which is our bucketer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sneak preview into the manual bucketing\n",
    "In order to perfrom the manual bucketing, the steps are the following:\n",
    "\n",
    "- The user defines the fine classing that is desired\n",
    "- Optionally, the user can then also run the statistical optimiziation\n",
    "- Once this is done, the whole pipeline is passed to thr `tweak_buckets` function\n",
    "- This will launch a web ui (that can run in a notebook, as well as in the browser), where the user can merge the buckets accoring to the desired logic.\n",
    "- If the statistical optimization is performed, a suggestion of the merging is presented.\n",
    "- After the buckets are adapted, the user can store the object and immediately continue with the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:02.876009Z",
     "start_time": "2020-10-14T22:10:02.433390Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from skorecard.pipeline import BucketingPipeline, tweak_buckets\n",
    "\n",
    "prebucket_pipeline = make_pipeline(DecisionTreeBucketer(variables=num_cols, max_n_bins=100, min_bin_size=0.05))\n",
    "bucket_pipeline = BucketingPipeline(make_pipeline(\n",
    "    OptimalBucketer(variables=num_cols, max_n_bins=10, min_bin_size=0.05),\n",
    "    OptimalBucketer(variables=cat_cols, max_n_bins=10, min_bin_size=0.05),\n",
    "))\n",
    "pipe = make_pipeline(prebucket_pipeline, bucket_pipeline)\n",
    "pipe.fit(X, y)\n",
    "\n",
    "pipe.transform(X).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Launch a web app where the manual tweaking can be done (this is still WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T22:10:02.943134Z",
     "start_time": "2020-10-14T22:10:02.877522Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tweak_buckets(pipe, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "http://127.0.0.1:8050/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
